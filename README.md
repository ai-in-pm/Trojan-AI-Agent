# LLM Trojan Attack Demonstration

This project demonstrates a simulated Trojan Horse attack on Large Language Models (LLMs) for educational purposes. It showcases how adversarial attacks can be executed and helps security researchers understand potential vulnerabilities.

## Overview

The demonstration implements an interactive AI Agent that shows how a Trojan Horse attack could potentially affect an LLM system. This is purely for educational purposes and includes safety measures to prevent real-world harm.

## Features

- Real-time demonstration of Trojan Horse attacks on LLMs
- Interactive interface for customizing attack parameters
- Educational resources and explanations
- Safety measures and ethical considerations
- Monitoring and evaluation tools

## Installation

```bash
pip install -r requirements.txt
```

## Usage

```bash
python main.py
```

The interface will open in your default web browser

You can:
Toggle the Trojan activation
Enter prompts to test the model's behavior
View attack statistics
Monitor the system's safety status

Key Features of the Implementation:

Trojan Attack Simulation:
Weight modification in specific layers
Trigger phrase detection
Controlled behavior modification
Safety measures to prevent real harm

Educational Components:
Real-time visualization of attack effects
Comprehensive statistics and monitoring
Clear explanations of the attack process
Safety warnings and ethical considerations

Safety Measures:
All attacks are simulated
Original model weights are preserved
No real damage to the target model
Clear warning messages

Interactive Learning:
Real-time response generation
Attack statistics monitoring
Customizable parameters
Educational context and explanations

The demonstration provides a safe, controlled environment to understand how Trojan Horse attacks could potentially affect LLMs, while maintaining strict safety measures to prevent any real harm.

## ## Safety Notice

This is an educational tool designed for cybersecurity research and learning. All demonstrations are conducted in a controlled environment with appropriate safety measures.

## Ethical Guidelines

1. This tool is for educational purposes only
2. No actual harmful attacks are performed
3. All demonstrations are contained within the simulation
4. User data and privacy are protected

## License

MIT License
